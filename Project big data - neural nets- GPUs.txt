Project big data - neural nets- GPUs

Αναλυτική Περιγραφή     (έως 5.000 λέξεις)
1) Ερευνητικά ερωτήματα/υποθέσεις εργασίας  (εισαγωγή στο πρόβλημα)
2) Εννοιολογικό πλαίσιο (περιγράφουμε της βασικές έννοιες)
3) Μεθοδολογία (παρουσιάζουμε την βασική μεθοδολογία μας: Αυτά που κάναμε ήδη)
4) Καινοτομία της ερευνητικής πρότασης
5) Συνεισφορά στη θεωρητική ή/και εφαρμοσμένη επιστημονική γνώση

Νέες προσεγγίσεις αλγορίθμων Μηχανικής Μάθησης κατάλληλων για Big Data σε παράλληλα και κατανεμημένα συστήματα GPUs

Parallel pipeline GPUs, Ensemble GPUs.

Η αναλυτική περιγραφή θα πρέπει να περιλαμβάνει σε διακριτή ενότητα τουλάχιστον τα παρακάτω:
1 Ερευνητικά ερωτήματα/υποθέσεις εργασίας
ΤΟ ΠΕΔΙΟ ΤΟΥ ΠΡΟΒΛΗΜΑΤΟΣ
Στην σημερινή εποχή των πολυσύνθετων συστημάτων και των big data ιδιαίτερα [Big Data 2013], τα διαθέσιμα δεδομένα αυξάνονται εκρηκτικά λόγω της ταχύτατης ανάπτυξης του διαδικτύου, των υπολογιστών, του ηλεκτρονικού εμπορίου, των τηλεπικοινωνιών και των ηλεκτρονικών συσκευών.
Με τη διαθεσιμότητα της ανέξοδης αποθήκευσης και την πρόοδο στην τεχνολογία συλλογής δεδομένων, πολλοί οργανισμοί και ινστιτούτα έχουν δημιουργήσει εξαιρετικά μεγάλες βάσεις δεδομένων και αποθήκες δεδομένων από επιχειρησιακά και επιστημονικά στοιχεία (CERN, NASA, remote sensing, astronomical serveys, human genome, network sensors, computer simulations παράγουν petabytes ανά έτος), και αυτή η τάση αναμένεται να αυξηθεί. Αφού οι βάσεις και οι αποθήκες δεδομένων είναι πολύ μεγάλες, υπάρχει συνεχόμενη ανάγκη για διερεύνηση μοντέλων και μεθόδων που επιτρέπουν παράλληλες τεχνικές Μηχανικής Μάθησης (Machine Learning) και ανακάλυψης γνώσης από δεδομένα. Χωρίς παραλληλισμό, είναι γενικά δύσκολο για ένα ενιαίο σύστημα επεξεργασίας να παρέχει λογικούς χρόνους απόκρισης.
Γενικά παρατηρείται ένα βασικό πρόβλημα το οποίο προσπαθούμε να αντιμετωπίσουμε και σε αυτή την ερευνητική πρόταση. Το πρόβλημα είναι ότι ο ρυθμός με τον οποίο εμφανίζονται στην βιβλιογραφία νέοι αλγόριθμοι Μηχανικής Μάθησης για δεδομένα μικρού/μεσαίου/μεγάλου μεγέθους είναι πάρα πολύ μεγάλος, ενώ σε αντίθεση ο ρυθμός με τον οποίο παρουσιάζονται νέοι αλγόριθμοι Μηχανικής Μάθησης κατάλληλοι για τεράστια σύνολα δεδομένων είναι εξαιρετικά μικρός. Οι δύο ρυθμοί είναι δυσανάλογοι. Δεν είναι πολλοί οι αλγόριθμοι Μηχανικής Μάθησης που μπορούν να θεωρηθούν κατάλληλοι για πολύ μεγάλους όγκους δεδομένων. Οι περισσότεροι είτε έχουν μεγάλη υπολογιστική πολυπλοκότητα (μεγαλύτερη από τετραγωνική Ο(Ν^2)), είτε απαιτούν μεγάλους πίνακες στην κεντρική μνήμη (μία τυπική Regression matrix, ή μία Hessian matrix, με 10,000 στήλες και 1,000,000 γραμμές χρειάζεται 80 Giga Byte και απλά δεν χωράει στη μνήμη) και αυτό είναι ένα πρόβλημα που μεγαλώνει με το χρόνο.
[Big Data 2013] V. Mayer-Schonberger and K. Cukier, Big Data: A Revolution That Will Transform How We Live, Work and Think, Houghton Mifflin Harcourt Publishing Company, 2013.

ΤΕΧΝΗΤΑ ΝΕΥΡΩΝΙΚΑ ΔΙΚΤΥΑ
Τα τεχνητά νευρωνικά δίκτυα (Artificial Neural networks -ANNs) έχουν αποδειχτεί πανίσχυρα αναλυτικά εργαλεία για την μη γραμμική στατιστική μοντελοποίηση δεδομένων. Τα νευρωνικά δίκτυα επεκτείνουν τις κλασσικές στατιστικές διαδικασίες, που κάνουν συχνά περιοριστικές υποθέσεις, αφαιρώντας αυτές τις υποθέσεις και επιτρέποντας έτσι σε σύνθετες, μη γραμμικές σχέσεις να μοντελοποιηθούν αποτελεσματικά. Μπορούν να χρησιμοποιηθούν για να λύσουν μια ευρεία ποικιλία προβλημάτων εμφανίζοντας ταυτόχρονα ευρωστία και ανοχή σε σφάλματα και στα δεδομένα εκπαίδευσης, και στην ίδια την δομή τους. Τα τεχνητά νευρωνικά δίκτυα έχουν εφαρμοστεί επιτυχώς στην αναγνώριση προτύπων, επεξεργασία σήματος και εικόνας, επιστημονική κατηγοριοποίηση, προσέγγιση συναρτήσεων, παλινδρόμηση, ανάλυση και πρόβλεψη χρονολογικών σειρών, αυτόματο έλεγχο, εργασίες ανακάλυψης γνώσης από δεδομένα, και πολλά πεδία της τεχνητής νοημοσύνης και Μηχανικής Μάθησης.
Ο ΣΤΟΧΟΣ
Έχουμε καταφέρει να δημιουργήσουμε νέες προσεγγίσεις και νέους αλγόριθμους Νευρωνικών Δικτύων και μηχανικής μάθησης για πολλά δεδομένα, που έως τώρα κλιμακώνονται εύκολα μέχρι 10,000,000 παραδείγματα με χρήση παράλληλης και κατανεμημένης επεξεργασίας. Θέλουμε να ανεβάσουμε το όριο και την ταχύτητα λειτουργία τους σε big data, με χρήση GPUs. Θέλουμε επίσης να διερευνήσουμε επεκτάσεις και βελτιώσεις των αλγορίθμων και τεχνικών αυτών που τρέχουμε ήδη καθώς και να εξετάσουμε εφαρμογές τους σε διαφορετικά προβλήματα big data.

ΟΙ ΠΛΕΥΡΕΣ ΤΟΥ ΠΡΟΒΛΗΜΑΤΟΣ
Η διαχείριση των big data είναι ένα πολύπλευρο πρόβλημα. Εκτός από τον όγκο τους τα big data παρουσιάζουν άλλα χαρακτηριστικά [Hu 2014] που τα διαχωρίζουν από τα παραδοσιακά δεδομένα. Ως εκ τούτου, ο σχεδιασμός κλιμακούμενων συστημάτων για ανάλυση big data αντιμετωπίζει πολλές τεχνικές προκλήσεις [Hu 2014]. Ενώ είναι δύσκολος ο χειρισμός του τεράστιου όγκου των δεδομένων, των διαφορετικών τύπων τους (static, dynamic, data streams κλπ) και των διαφορετικών μορφών τους (format), γίνεται περισσότερο δύσκολο να βγάλουμε λογικά συμπεράσματα από αυτά, μέσω της ανακάλυψης χρήσιμης γνώσης.
 [Hu 2014] H. Hu, Y.Wen, T.-S. Chua, and X. Li, “Toward scalable systems for big data analytics: a technology tutorial,” IEEE Access, vol. 2, pp. 652–687, 2014.
Η πλειοψηφία των συστημάτων και εφαρμογών για big data, συνήθως αποτελούν το κάθε ένα μία λύση εντοπισμένη σε συγκεκριμένο ξεχωριστό πρόβλημα, για αυτό και στρέφονται στα παραδοσιακά παραδείγματα υπολογιστικής. Μέχρι πρόσφατα τομείς big data υπήρχαν μόνο σε εξειδικευμένα πεδία εφαρμογής, όπως της Μετεωρολογίας, πειραματικής Φυσικής, Internet analytics. Σήμερα, οι εφαρμογές big data εισχωρούν σε πιο γενικά πεδία έρευνας όπως της βιολογίας, ιατρικής επιστήμης, γενετικής, βιοϊατρικής και βιοπληροφορικής. Σήμερα, οι μεγάλες εταιρίες αναγκάζονται να έχουν ειδικά τμήματα big data τα οποία είναι επιφορτισμένα να αποθηκεύουν καθημερινά μεγάλους όγκους δεδομένων και τα διατηρούν για πιθανή μελλοντική ανάλυση. Τα big data γίνονται κομμάτι της καθημερινότητας.
Ο όγκος των δεδομένων αυξάνεται εκθετικά. Πρόσφατες μελέτες που συνοψίζονται στην [Gantz 2012] δείχνουν ότι οι ποσότητες των δεδομένων διπλασιάζονται κάθε 2 χρόνια. Έτσι προβλέπεται ότι ο συνολικός όγκος δεδομένων θα αυξηθεί από 130 exabytes που ήταν το έτος 2005, σε πάνω από 40,000 exabytes το έτος 2020. Έτσι η σημερινή κατάσταση δείχνει ότι ο ρυθμός αύξησης στην επεξεργαστική ισχύ είναι μικρότερος από το ρυθμό αύξησης του όγκου δεδομένων. Με την αναμενόμενη χρήση των τεχνολογιών που συλλέγουν δεδομένα, όπως Internet Of Things, Wireless Sensor Networks, ο ρυθμός αύξησης του όγκου δεδομένων θα μεγαλώσει ακόμη περισσότερο.
Νέες προσεγγίσεις, μέθοδοι και αλγόριθμοι προς την κατεύθυνση Μηχανικής Μάθησης και ανακάλυψης γνώσης από μεγάλους όγκους δεδομένων είναι επιτακτικές.
[Gantz 2012] J. Gantz and D. Reinsel, “The digital universe in 2020: big data, bigger digital shadows, and biggest growth in the far East,” in Proceedings of the IDC iView, IDC: Analyze the Future, 2012.

Εδώ περιγράφουμε τι θα κάνουμε (Parallel pipeline GPUs, Ensemble GPUs).
Δηλαδή θα μετρήσουμε μόνο τους χρόνους? Όχι,  θα πρέπει να δοκιμάσουμε και νέες προσεγγίσεις που θα είναι επιτρέπουν τον συγκερασμό των παράλληλων και κατανεμημένων αλγορίθμων Μηχανικής Μάθησης που έχουμε αναπτύξει έως τώρα, με τα συστήματα GPUs.

2 Εννοιολογικό πλαίσιο
Σε αυτή την ενότητα περιγράφουμε της βασικές έννοιες για το τι είναι machine learning and data mining, clustering, classification, regression, neural networks, Ensembles και Committees.
ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ (Machine Learning)
Κατά την διάρκεια της μάθησης ο άνθρωπος (ή ένα σύστημα) αλλάζει εσωτερικά, μαθαίνει και προσαρμόζεται συνεχώς στα εξωτερικά ερεθίσματα από το περιβάλλον του. Οι ανθρώπινες προσπάθειες μίμησης αυτής της διαδικασίας με χρήση υπολογιστικών μηχανών και μαθηματικών μοντέλων περιγράφονται από την Μηχανική Μάθηση. Η Μηχανική Μάθηση [Mitchell 1997] [Hastie 2008] [Smola 2010] [Welling 2010], ένας κλάδος της τεχνητής νοημοσύνης, είναι μία περιοχή έρευνας για το σχεδιασμό και ανάπτυξη αλγορίθμων που επιτρέπουν στους υπολογιστές να εξελίξουν συμπεριφορές βασισμένες σε εμπειρικά δεδομένα, όπως αυτά που προέρχονται από αισθητήρες ή βάσεις δεδομένων. Οι αλγόριθμοι Μηχανικής Μάθησης χρησιμοποιούνται ευρύτατα και στην ακαδημαϊκή κοινότητα και στην βιομηχανία και στις επιχειρήσεις λύνοντας πολλά πραγματικά προβλήματα. Τα δεδομένα είναι παραδείγματα που περιγράφουν συσχετίσεις μεταξύ παρατηρούμενων μεταβλητών. Ένας αλγόριθμος μάθησης από παραδείγματα πρέπει να μπορεί να συλλάβει τα χαρακτηριστικά της άγνωστης κατανομής πιθανότητας που περιγράφει τα δεδομένα αυτά. Σημαντικό κομμάτι έρευνας στη Μηχανική Μάθηση αποτελεί η αυτόματη αναγνώριση σύνθετων προτύπων. Η δυσκολία βρίσκεται στο γεγονός ότι όλα τα πιθανά μοντέλα όλων των πιθανών δεδομένων εισόδου είναι πάρα πολλές για να καλυφθούν από το σύνολο των παραδειγμάτων εκπαίδευσης. Έτσι ο αλγόριθμος μάθησης πρέπει να γενικεύσει από τα παραδείγματα, ώστε να είναι σε θέση να παραγάγει μια χρήσιμη εκτίμηση σε νέες υποθέσεις. Την τελευταία δεκαετία, λόγω της εκθετικής αύξησης των διαθέσιμων δεδομένων η Μηχανική Μάθηση έχει γίνει κομμάτι της καθημερινότητας (για να δείτε ένα παράδειγμα ανοίξτε τον υπολογιστή και κάντε μία αναζήτηση στο Internet που θα σας εμφανίσει τα αποτελέσματα με τη μορφή εξατομικευμένων προτάσεων, σύμφωνα με τις αναζητήσεις που έχετε κάνει στο παρελθόν και σύμφωνα με το προφίλ χρήστη που έχει μάθει ο αλγόριθμος Μηχανικής Μάθησης για εσάς). Η τεράστια αύξηση των δεδομένων έχει αλλάξει την ροή έρευνας από εξεζητημένους αλγόριθμους υψηλής πολυπλοκότητας που λειτουργούν μόνο με λίγα δεδομένα, προς την κατεύθυνση εύρεσης λιγότερο πολύπλοκων αλγορίθμων που μπορούν όμως να λειτουργήσουν με μεγάλους όγκους δεδομένων. Μερικές υποκατηγορίες και μέθοδοι της Μηχανικής Μάθησης τις οποίες μελετήσαμε έως τώρα είναι Artificial Neural Networks [INS 2015] [EANN 2013] [BCI 2013] [SETN 2012][JCS 2016] [ICTAI 2012] [Neucom 2015] [PCI 2015] [AIAI 2014] [AIRE 2014] [IISA 2013] [AIAI 2012], kernel based methods [NCA 2016] [EANN 2015], clustering algorithms [AIAI 2016], Bayesian methods [BCI 2013] [SETN 2012][JCS 2016], Ensembles [Neucom 2015] [PCI 2015] [AIAI 2014], Committee Machines [AIRE 2014] [IISA 2013] [AIAI 2012].
[Mitchell 1997] Mitchell T., Machine Learning. Burr Ridge, IL: Mcgraw Hill, 1997.
[Hastie 2008] T. Hastie, R. Tibshirani and J. Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition, Springer 2008
[Smola 2010] Smola A. and Vishwanathan S.V.N., Introduction to Machine Learning, Cambridge University Press 2010.
[Welling 2010] Welling M., A First Encounter with Machine Learning, Donald Bren School of Information and Computer Science, University of California Irvine, 2010

CLUSTERING : Η Συσταδοποίηση (clustering, Unsupervised learning, Segmentation, Partitioning) είναι η διαδικασία ομαδοποίησης αντικειμένων με όμοια χαρακτηριστικά και η κατάταξη σε συστάδες ή συμπλέγματα. Στην Συσταδοποίηση οι συστάδες δεν είναι προκαθορισμένες αλλά προσδιορίζονται από τα δεδομένα. Η συσταδοποίηση αναφέρεται εναλλακτικά και σαν μη εποπτευόμενη μάθηση. Μπορεί να θεωρηθεί σαν μια διαμέριση ή τμηματοποίηση των δεδομένων σε ομάδες που μπορεί να είναι ή να μην είναι διακριτές μεταξύ τους. Η συσταδοποίηση συνήθως επιτυγχάνεται με τον καθορισμό της ομοιότητας, ως προς προκαθορισμένα γνωρίσματα, ανάμεσα στα δεδομένα. Τα πιο σχετικά δεδομένα ομαδοποιούνται σε ίδιες ομάδες. Έως τώρα έχουμε δημοσιεύσει έναν δικό μας αλγόριθμο στην εργασία [AIAI 2016].
CLASSIFICATION: Η κατηγοριοποίηση, (classification, Supervised learning) αντιστοιχίζει τα δεδομένα σε προκαθορισμένες κατηγορίες ή κλάσεις. Αναφέρεται συχνά σαν εποπτευόμενη μάθηση επειδή οι κατηγορίες– κλάσεις καθορίζονται πριν ακόμη εξεταστούν τα δεδομένα. Οι αλγόριθμοι κατηγοριοποίησης, οι γνωστοί ταξινομητές, απαιτούν οι κατηγορίες να ορίζονται με βάση τις τιμές των γνωρισμάτων των δεδομένων, και περιγράφουν αυτές τις κατηγορίες εξετάζοντας τα γνωρίσματα  αυτά. Μέχρι τώρα έχουμε ερευνήσει αλγορίθμους και εφαρμογές Κατηγοριοποίησης μέσω Νευρωνικών Δικτύων στις εργασίες [INS 2015] [EANN 2013] [BCI 2013] [SETN 2012][JCS 2016] [ICTAI 2012] [Neucom 2015] [PCI 2015] [AIAI 2014] [AIRE 2014] [IISA 2013] [AIAI 2012].
REGRESSION: Η Παλινδρόμηση (Regression) είναι μια ευρέως χρησιμοποιημένη στατιστική τεχνική μοντελοποίησης για την έρευνα της συσχέτισης μεταξύ μίας εξαρτώμενης μεταβλητής και μιας ή περισσότερων ανεξάρτητων μεταβλητών. Έτσι η παλινδρόμηση μπορεί να απεικονίζει ένα στοιχειώδες δεδομένο x σε μια πραγματική μεταβλητή πρόβλεψης y. Η παλινδρόμηση περιλαμβάνει την εκμάθηση μιας συνάρτησης y=f(x) που κάνει αυτή την απεικόνιση. Η παλινδρόμηση προϋποθέτει ότι τα σχετικά δεδομένα ταιριάζουν με μερικά γνωστά είδη συνάρτησης (γραμμική, μη-γραμμική, πολυωνυμική κλπ.) και μετά καθορίζει την καλύτερη συνάρτηση αυτού του είδους που μοντελοποιεί τα δεδομένα. Τα Τεχνητά νευρωνικά δίκτυα χρησιμοποιούνται ευρύτατα για εκτίμηση σημείων, εκτίμηση συνάρτησης, παλινδρόμηση, πρόβλεψη, κατηγοριοποίηση. Έως τώρα έχουμε ερευνήσει αλγορίθμους και εφαρμογές Παλινδρόμησης μέσω Νευρωνικών Δικτύων στις εργασίες [COIN 2017] [NCA 2016] [EANN 2015] [PCI 2015].
NEURAL NETWORKS: Τα τεχνητά νευρωνικά δίκτυα (artificial neural networks - ANN) είναι μία προσπάθεια εφαρμογής των αρχών λειτουργίας του ανθρωπίνου εγκεφάλου, με μοντελοποίηση και κατανόηση των απλών λειτουργιών του και δυνατότητες υλοποίησης. Υποστηρίζουν έτσι μη γραμμικότητα, έχουν απλές υπολογιστικές μονάδες και μεγάλο αριθμό συνδέσεων (συνάψεων). Τα προβλήματα που καλούνται να λύσουν είναι Προσέγγιση συνάρτησης, αναγνώριση προτύπων, κατηγοριοποίηση, Ομαδοποίηση, Πρόβλεψη σημάτων, αναγνώριση συστημάτων, Συσχετιστική μνήμη, εξαγωγή χαρακτηριστικών, Αυτόματος έλεγχος, Βελτιστοποίηση κ.α. Πολλά βασικά χαρακτηριστικά του ανθρώπινου εγκεφάλου που λείπουν από τις αρχιτεκτονικές των υπολογιστών τύπου von Neumann, αλλά απαντώνται σε ένα βαθμό στα τεχνητά νευρωνικά δίκτυα είναι: μη-γραμμικότητα, Μαζική παραλληλία,  Κατανεμημένη αναπαράσταση, Κατανεμημένη επεξεργασία, Ικανότητα μάθησης, Ικανότητα γενίκευσης, Ικανότητα αφαίρεσης, Προσαρμοστικότητα, Ανοχή σε σφάλματα. Τα τεχνητά νευρωνικά δίκτυα είναι μια συλλογή από νευρώνες (μονάδες επεξεργασίας) που συνδέονται μεταξύ τους με συνάψεις/συνδέσεις. Κάθε νευρώνας έχει πολλές εισόδους αλλά μόνο μία έξοδο η οποία με τη σειρά της μπορεί να αποτελέσει είσοδο για άλλους νευρώνες. Οι συνδέσεις μεταξύ των νευρώνων διαφέρουν ως προς τη σημαντικότητά τους, η οποία και προσδιορίζεται από το συντελεστή βάρους. Η επεξεργασία μέσα σε κάθε νευρώνα καθορίζεται από τη συνάρτηση μεταφοράς, η οποία καθορίζει την κάθε έξοδο σε σχέση με τις εισόδους και τους συντελεστές βάρους. Η εκπαίδευση των νευρωνικών δικτύων μπορεί να θεωρηθεί μία μέθοδος εύρεσης των βέλτιστων παραμέτρων και βαρών τους. Μέχρι τώρα έχουμε ερευνήσει τους ακόλουθους τύπους Νευρωνικών Δικτύων:
Regularization Networks [NCA 2016] [EANN 2015]
Hierarchical Radial Basis Function Neural Networks [INS 2015] [EANN 2013]
Probabilistic Neural Networks [BCI 2013] [SETN 2012][JCS 2016]
Radial Basis Probabilistic Neural Network [ICTAI 2012]
Incremental Extreme Learning Machines [COIN 2017]
Ensembles of several neural networks [Neucom 2015] [PCI 2015] [AIAI 2014]
Committee Machine of several neural networks [AIRE 2014] [IISA 2013] [AIAI 2012]
ENSEMBLES AND COMMITTEE MACHINES: Οι Κατανεμημένοι ταξινομητές είναι τα πιο γνωστά παραδείγματα των αλγορίθμων κατανεμημένης εξόρυξης γνώσης. Τέτοιοι αλγόριθμοι βασίζονται στην προσέγγιση των ομάδων ταξινομητών (Ensembles) [Dietterich 2000]. Οι ομάδες ταξινομητών εμφανίστηκαν για να βελτιώσουν την ακρίβεια των μοντέλων μάθησης. Στην πράξη, πολλαπλά μοντέλα εξάγονται από ομοιογενείς διαμερίσεις των δεδομένων χρησιμοποιώντας και διαφορετικές μεθόδους. Τα τοπικά μοντέλα συναθροίζονται με την υιοθέτηση ενός (σταθμισμένου ή όχι) σχήματος ψηφοφορίας (voting). Αυτή η προσέγγιση μπορεί να πραγματοποιηθεί απευθείας σε ένα κατανεμημένο περιβάλλον (αν κάθε πηγή δεδομένων έχει ένα αντιπροσωπευτικό υποσύνολο δεδομένων). Έως τώρα έχουμε ερευνήσει αλγορίθμους που αφορούν Ensembles και Committee Machines Νευρωνικών Δικτύων στις εργασίες [Neucom 2015] [PCI 2015] [AIAI 2014] [AIRE 2014] [IISA 2013] [AIAI 2012].

3 Μεθοδολογία
Σε αυτό την ενότητα παρουσιάζουμε την βασική μεθοδολογία για Παράλληλους και κατανεμημένους αλγόριθμους (από την διατριβή) , GPUs κλπ
ΠΡΕΠΕΙ ΝΑ ΒΑΛΩ ΚΑΙ ΜΕΡΙΚΑ ΑΠΟ ΤΟ ABSTRACT
ΝΑ ΔΕΙΞΩ ΑΥΤΑ ΠΟΥ ΚΆΝΑΜΕ ΗΔΗ
Για μία περίοδο τριών δεκαετιών τα τεχνητά νευρωνικά δίκτυα, η παράλληλη και κατανεμημένη επεξεργασία και η Μηχανική Μάθηση με την ανακάλυψη γνώσης από δεδομένα συνεχίζουν να αναπτύσσονται και να εξελίσσονται. Όλο και περισσότερο συχνότερα στις μέρες μας συνεργάζονται και συνδυάζονται μεταξύ τους λόγω των καθημερινών και αυξημένων αναγκών για ανάλυση μεγάλων όγκων δεδομένων.

DATA- TASK PARALLELISM
Ο παραλληλισμός δεδομένων (data parallelism) αναφέρεται στην εκτέλεση της ίδιας λειτουργίας ή εντολής σε πολλαπλά μεγάλα υποσύνολα δεδομένων συγχρόνως. Αυτό είναι σε αντίθεση με τον παραλληλισμό διεργασιών (task parallelism), που λέγεται και παραλληλισμός ελέγχου ή παραλληλισμός λειτουργιών, ο οποίος αναφέρεται στην ταυτόχρονη εκτέλεση πολλαπλών διαδικασιών ή εντολών. Παρά τα πλεονεκτήματα του παραλληλισμού δεδομένων, πρέπει να υπογραμμιστεί ότι η αξιοποίηση του παραλληλισμού διεργασιών είναι επίσης κρίσιμης σημασίας στην εξόρυξη γνώσης από δεδομένα. Αξίζει να σημειωθεί ότι ο παραλληλισμός δεδομένων και διεργασιών δεν είναι αμοιβαία αποκλειόμενοι. Εάν είναι διαθέσιμος ένας αρκετά μεγάλος αριθμός επεξεργαστών, και οι δύο τύποι παραλληλισμών μπορούν να χρησιμοποιηθούν συγχρόνως, οι οποίοι μπορούν να επιταχύνουν πολύ την εκτέλεση των αλγορίθμων εξόρυξης. Αν και αυτό αποτελεί μεγάλη πρόκληση, όταν υλοποιείται ένας τέτοιος υβριδικός παραλληλισμός είναι συνήθως πολύ αποτελεσματικός. Αυτός ο υβριδικός data-task parallelism είναι η κύρια βάση των περισσότερων έως τώρα εργασιών μας πάνω στο θέμα και αποτελεί και την βάση πάνω στην οποία θα συνεχίσουμε αυτή την έρευνα επεκτείνοντας την στα συστήματα GPUs.

GPUs
Παρότι ο τυπικός παραλληλισμός μειώνει το χρόνο επεξεργασίας, αυτό δεν είναι από μόνο του αρκετό, καθότι ο αρχικός χρόνος υπολογισμού T στην καλύτερη περίπτωση διαιρείται δια τον αριθμό των επεξεργαστών Τ/P, και έτσι έχουμε επιτάχυνση P φορές. Η χρήση πολλών CPUs δεν είναι από μόνη της αρκετή. Χρειάζεται μία πιο εξελιγμένη αρχιτεκτονική που θα βασίζεται σε GPUs που πλεονεκτούν έναντι των απλών CPUs σε ταχύτητα. Πρέπει λοιπόν σε κάθε έναν επεξεργαστή να εφαρμοστεί επιτάχυνση των τοπικών διεργασιών με επιπλέον χρήση GPUs.

ENSEMBLE GPUs


4 Καινοτομία της ερευνητικής πρότασης
Η καινοτομία της ερευνητικής πρότασης και ο βασικός στόχος είναι η αντιστοίχηση των μοντέλων εκμάθησης (task) και των δεδομένων (data) σε δύο αρχιτεκτονικές:
          αρχιτεκτονική parallel ring pipeline task-data
          αρχιτεκτονική distributed task-data
 που επιτρέπουν την εκμάθηση μεγάλων μοντέλων (που είναι κατανεμημένα σε πολλούς επεξεργαστές) από μεγάλο σύνολο δεδομένων (που είναι κατανεμημένο σε πολλούς επεξεργαστές).

Α)  αρχιτεκτονική data-task parallelism in a ring pipeline
For dealing with the scalability problem we propose parallel mappings in a Ring pipeline. In order to facilitate constructing a large scale distributed model on a large scale distributed dataset we demonstrate that the entire learning scheme can use simultaneously data-neuron partitioning across many processors. While this partitioning complicates the data-task dependency graph and maximizes the communication overhead the processors can be organized in a virtual ring pipeline.
What the ring pipeline architecture does is to minimize communication links between the processors by reducing the data-task dependency graph into a cycle, where we can adopt the {send-compute-receive} pattern which also permits to overlap the computation delays with the communication delays.
What the ring pipeline architecture does is: 1) reduce the data-task dependency graph into a cycle, 2) minimizes the number of communication links, 3) can use the {send-compute-receive} pattern that permits overlapping computation delays with communication delays.
Hence, the essence of the data-neuron parallelism we employ is based on this ring pipeline parallel architecture, which is known for not suffering from common scalability problems, communication delays and bottleneck effects. It allows each processor node to hold a part of the neurons in the learning model together with a part of the training data.
In fig. 1.2(c) we especially adopt the Ring pipeline parallel architecture for data-task parallelism. In the ring pipelining every processor has a portion of tasks (neurons) and a portion of the training data. There is a single program all processors execute with no synchronization points. Like pipeline every processor passes a message to its next and receives a message from its previous.
Η αρχιτεκτονική παράλληλης σωληνωτής επεξεργασίας σε δακτύλιο επιτρέπει την εκπαίδευση ενός μεγάλου μοντέλου μάθησης που κατανέμεται σε πολλούς επεξεργαστές, χρησιμοποιώντας ένα μεγάλο σύνολο δεδομένων που είναι και αυτό κατανεμημένο σε πολλούς επεξεργαστές. Την αρχιτεκτονική παράλληλης σωληνωτής επεξεργασίας σε δακτύλιο την έχουμε ήδη επιτυχημένα χρησιμοποιήσει στην εργασία [JCS 2016].

Β) Αρχιτεκτονική Distributed Task-Data
Τυπικά οι κατανεμημένοι αλγόριθμοι ανακάλυψη γνώσης σχεδιάζονται σύμφωνα με τον πιθανό παραλληλισμό που μπορούν να εφαρμόσουν πάνω στα κατανεμημένα δεδομένα, καθώς τα δεδομένα αυτά δεν μπορούν να συγκεντρωθούν σε έναν κεντρικό server. Η κατανεμημένη μάθηση και ανακάλυψη γνώσης από απομονωμένες τοποθεσίες δεδομένων (κλειστά συστήματα όπου κάθε επεξεργαστής έχει πρόσβαση στο δικό του υποσύνολο δεδομένων) είναι μία στρατηγική ανεξάρτητου παραλληλισμού που χρησιμοποιεί ασύγχρονη μεταβίβαση μηνυμάτων (asynchronous message passing). Η ανταλλαγή μηνυμάτων είναι όλοι-με-όλους (all-to-all).

Κάθε επεξεργαστής έχει ένα πλήρες νευρωνικό μοντέλο (εδώ κάθε task είναι ένα μοντέλο) που εκπαιδεύεται με ένα υποσύνολο δεδομένων. Κατά συνέπεια περιλαμβάνουν τοπική ανάλυση δεδομένων, που ακολουθείται από την παραγωγή ενός καθολικού μοντέλου μέσω της συνάθροισης των τοπικών μοντέλων. Στη συνέχεια όλα τα τοπικά μοντέλα αθροίζονται για να παραγάγουν το τελικό μοντέλο περιγραφής. Αυτή την αρχιτεκτονική για κατανεμημένη μάθηση και ανακάλυψη γνώσης με Νευρωνικά Δίκτυα την έχουμε ήδη επιτυχημένα χρησιμοποιήσει σε αρκετές πρόσφατες εργασίες [Neucom 2015][AIRE 2014] [IISA 2013] [AIAI 2012].



5 Συνεισφορά στη θεωρητική ή/και εφαρμοσμένη επιστημονική γνώση
CLUSTERING
Έχουμε πρόσφατα δημοσιεύσει έναν νέο αλγόριθμο, τον KG-SC (Kernel Gradient Subtractive Clustering) [AIAI 2016] για αυτοματοποιημένο exemplar selection και Clustering, που είναι από τις βασικότερες λειτουργίες στο πεδίο Machine Learning και Data Mining. Είναι αρκετά εύκολο να δοκιμάσουμε τον KG-SC σε πολλά δεδομένα (για τα big data χρειάζεται να κάνουμε ένα dual tree), και να τον επεκτείνουμε επίσης σε Ιεραρχικό KG-SC, Streaming KG-SC, constrained KG-SC καθώς και Semi-Supervised ή Supervised KG-SC.
LOW RANK KERNEL MATRIX APPROXIMATION
Θα χρησιμοποιήσουμε τον αλγόριθμο KG-SC σε GPUs για Kernel matrix low rank approximation στα large scale Regularization Networks.
PARALLEL CLASSIFICATION
Με τον παράλληλο αλγόριθμο KG-SC σε GPUs και τον παράλληλο mini-batch gradient descent σε GPUs θα μπορούμε πλέον να υλοποιήσουμε: 1) Parallel mini-batch gradient descent for multi-output RBFNN (Radial Basis Function Neural Network) classifier, 2) Semi-Supervised Radial Basis Function Neural Networks, 3) Minimum Class-Variance guided RBFNN multi-output classifier

DISTRIBUTED ENSEMBLES FOR CLASSIFICATION
The weight base ensemble selection by using non-negative regularized least squares could be examined in the context of other models, like multi-label classification, that similarly require pruning.

Regression

DENSITY ESTIMATION ΣΕ GPUS
Θα χρησιμοποιήσουμε τον αλγόριθμο KG-SC σε GPUs μαζί με τον αλγόριθμο Expectation-Maximization σε GPUs για Density Estimation.

Ενδεχόμενη συμπερίληψη βιβλιογραφίας δεν προσμετρείται στον αριθμό των λέξεων

ΒΙΒΛΙΟΓΡΑΦΙΑ
[COIN 2017] Yiannis Kokkinos and Konstantinos G. Margaritis (2017) “Big data regression with Parallel Enhanced and Convex Incremental Extreme Learning Machines”, Computational Intelligence, accepted 2017.
[NCA 2016] Yiannis Kokkinos and Konstantinos G. Margaritis (2016) “Local Learning Regularization Networks for localized regression”. Neural Computing and Applications. DOI :10.1007/s00521-016-2569-0
[JCS 2016] Yiannis Kokkinos and Konstantinos G. Margaritis (2016) “Simulating parallel scalable Probabilistic Neural Networks via exemplar selection and EM in a Ring Pipeline”, Journal of Computational Science, under review
[AIAI 2016] Yiannis Kokkinos and Konstantinos G. Margaritis (2016) “Exemplar selection via leave-one-out kernel averaged gradient descent and Subtractive Clustering”, (AIAI 2016), Springer Lecture Notes in Computer Science, IFIP AICT 475, pages 1–13
 [EANN 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015), “Multithreaded Local Learning Regularization Neural Networks for regression tasks”, (EANN 2015), Communications in Computer and Information Science, CCIS 517, pages 129–138
[PCI 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015). “A fast progressive Local Learning regression ensemble of Generalized Regression Neural Networks”. In PCI 2015
[INS 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015) “Topology and simulations of Hierarchical Markovian Radial Basis Function Neural Network classifier”, Information Sciences, vol. 294, pages 612−624.
[Neucom 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015) “Confidence ratio Affinity Propagation in ensemble selection of neural network classifiers for distributed privacy-preserving data mining”, Neurocomputing, 150, pages 513−528.
[AIRE 2014] Yiannis Kokkinos and Konstantinos G. Margaritis (2014) “A distributed privacy-preserving regularization network committee machine of isolated Peer classifiers for P2P data mining”, Artificial Intelligence Review, 42(3), pages 385−402.
[AIAI 2014] Yiannis Kokkinos and Konstantinos G. Margaritis (2014) “Breaking ties of plurality voting in ensembles of distributed neural network classifiers using soft max accumulations”, (AIAI 2014), Springer Lecture Notes in Computer Science, IFIP AICT 436, pages 20–28.
[IISA 2013] Yiannis Kokkinos and Konstantinos G. Margaritis (2013) “Distributed privacy-preserving P2P data mining via Probabilistic Neural Network Committee Machines”, in 4th International Conference on Information, Intelligence, Systems, and Applications (IISA 2013)
[BCI 2013] Yiannis Kokkinos and Konstantinos G. Margaritis (2013) “Parallel and local learning for fast Probabilistic Neural Networks in scalable data mining”, in BCI 2013.
[EANN 2013] Yiannis Kokkinos and Konstantinos G. Margaritis (2013) “A Parallel and Hierarchical Markovian RBF Neural Network: preliminary performance evaluation”, (EANN 2013), Springer Lecture Notes in Computer Science, Part I, CCIS 383, pages 340–349
[SETN 2012] Yiannis Kokkinos and Konstantinos G. Margaritis (2012) “Parallelism, localization and chain gradient tuning combinations for fast scalable Probabilistic Neural Networks in data mining applications”,  Springer Lecture Notes in Artificial Intelligence 7297, pages 41–48.
[AIAI 2012] Yiannis Kokkinos and Konstantinos G. Margaritis (2012) “A Regularization Network committee machine of isolated Regularization Networks for distributed privacy preserving data mining”, (AIAI 2012), Springer Lecture Notes in Computer Science, IFIP AICT 381, pages 97–106.
[ICTAI 2012] Yiannis Kokkinos and Konstantinos G. Margaritis (2012) “A Parallel Radial Basis Probabilistic Neural Network for scalable data mining in distributed memory machines”, 24th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2012.
