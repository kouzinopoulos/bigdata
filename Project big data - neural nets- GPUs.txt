Project Μεγάλα Δεδομένα - neural nets- GPUs

Αναλυτική Περιγραφή     (έως 5.000 λέξεις)
1) Ερευνητικά ερωτήματα/υποθέσεις εργασίας  (εισαγωγή στο πρόβλημα)
2) Εννοιολογικό πλαίσιο (περιγράφουμε της βασικές έννοιες)
3) Μεθοδολογία (παρουσιάζουμε την βασική μεθοδολογία μας: Αυτά που κάναμε ήδη)
4) Καινοτομία της ερευνητικής πρότασης
5) Συνεισφορά στη θεωρητική ή/και εφαρμοσμένη επιστημονική γνώση

Νέες προσεγγίσεις αλγορίθμων Μηχανικής Μάθησης κατάλληλων για Μεγάλα Δεδομένα σε παράλληλα και κατανεμημένα συστήματα Μονάδων Επεξεργασίας Γραφικών

Parallel pipeline GPUs, Ensemble GPUs.

Η αναλυτική περιγραφή θα πρέπει να περιλαμβάνει σε διακριτή ενότητα τουλάχιστον τα παρακάτω:
1 Ερευνητικά ερωτήματα/υποθέσεις εργασίας
ΤΟ ΠΕΔΙΟ ΤΟΥ ΠΡΟΒΛΗΜΑΤΟΣ
Στην σημερινή εποχή των πολυσύνθετων συστημάτων και των Μεγάλων Δεδομένων (Μεγάλα Δεδομένα) ιδιαίτερα [Mayer-Schonberger 2013], τα παραγώμενα δεδομένα στους τομείς της Έρευνας, του Διαδικτύου, του ηλεκτρονικού εμπορίου και των τηλεπικοινωνιών αυξάνονται εκρηκτικά με τον χρόνο.

Με την πρόοδο στην τεχνολογία συλλογής δεδομένων, πολλοί οργανισμοί και ινστιτούτα έχουν δημιουργήσει εξαιρετικά μεγάλες βάσεις δεδομένων από επιχειρησιακά και επιστημονικά στοιχεία (CERN, NASA, remote sensing, astronomical surveys, human genome, network sensors, computer simulations παράγουν petabytes ανά έτος) με συνεχώς αυξανόμενο ρυθμό. Για αυτό το λόγο, υπάρχει συνεχόμενη ανάγκη για διερεύνηση μοντέλων και μεθόδων που επιτρέπουν παράλληλες τεχνικές Μηχανικής Μάθησης (Machine Learning) και ανακάλυψης γνώσης από δεδομένα. Χωρίς παραλληλισμό, είναι εξαιρετικά δύσκολο για ένα σειριακό σύστημα επεξεργασίας να παρέχει λογικούς χρόνους απόκρισης στους χρήστες.
Ο ρυθμός όμως με τον οποίο εμφανίζονται στην βιβλιογραφία νέοι αλγόριθμοι Μηχανικής Μάθησης για δεδομένα μικρού/μεσαίου/μεγάλου μεγέθους είναι πάρα πολύ μεγάλος, ενώ αντίθετα ο ρυθμός με τον οποίο παρουσιάζονται νέοι αλγόριθμοι Μηχανικής Μάθησης κατάλληλοι για Μεγάλα Δεδομένα είναι εξαιρετικά μικρός. Οι δύο ρυθμοί είναι δυσανάλογοι. Δεν είναι πολλοί οι αλγόριθμοι Μηχανικής Μάθησης που μπορούν να θεωρηθούν κατάλληλοι για πολύ μεγάλους όγκους δεδομένων. Οι περισσότεροι είτε έχουν μεγάλη υπολογιστική πολυπλοκότητα (μεγαλύτερη από τετραγωνική Ο(Ν2)), είτε απαιτούν μεγάλους πίνακες στην κεντρική μνήμη του Υπολογιστή (για παράδειγμα ένα τυπικό Regression matrix, ή Hessian matrix, με 10,000 στήλες και 1,000,000 γραμμές χρειάζεται περίπου 80 Gigabyte με αποτέλεσμα να είναι σχεδόν αδύνατη η αποθήκευση του στη μνήμη) και αυτό είναι ένα πρόβλημα που μεγαλώνει με το χρόνο.
[Mayer-Schonberger 2013] V. Mayer-Schonberger and K. Cukier, Big Data: A Revolution That Will Transform How We Live, Work and Think, Houghton Mifflin Harcourt Publishing Company, 2013.

ΤΕΧΝΗΤΑ ΝΕΥΡΩΝΙΚΑ ΔΙΚΤΥΑ
Τα τεχνητά νευρωνικά δίκτυα (Artificial Neural networks -ANNs) έχουν αποδειχτεί πανίσχυρα αναλυτικά εργαλεία για τη μη γραμμική στατιστική μοντελοποίηση δεδομένων. Τα νευρωνικά δίκτυα επεκτείνουν τις κλασσικές στατιστικές διαδικασίες, που κάνουν συχνά περιοριστικές υποθέσεις, αφαιρώντας αυτές τις υποθέσεις και επιτρέποντας έτσι σε σύνθετες, μη γραμμικές σχέσεις να μοντελοποιηθούν αποτελεσματικά. Μπορούν να χρησιμοποιηθούν για να λύσουν μια ευρεία ποικιλία προβλημάτων εμφανίζοντας ταυτόχρονα ευρωστία και ανοχή σε σφάλματα και στα δεδομένα εκπαίδευσης, και στην ίδια την δομή τους. Τα τεχνητά νευρωνικά δίκτυα έχουν εφαρμοστεί επιτυχώς στην αναγνώριση προτύπων, την επεξεργασία σήματος και εικόνας, στην επιστημονική κατηγοριοποίηση, προσέγγιση συναρτήσεων, παλινδρόμηση, ανάλυση και πρόβλεψη χρονολογικών σειρών, στον αυτόματο έλεγχο, σε εργασίες ανακάλυψης γνώσης από δεδομένα, καθώς και σε πολλά πεδία της τεχνητής νοημοσύνης και Μηχανικής Μάθησης.
Ο ΣΤΟΧΟΣ
Έχουμε καταφέρει να δημιουργήσουμε νέες προσεγγίσεις και νέους αλγόριθμους Νευρωνικών Δικτύων και μηχανικής μάθησης για πολλά δεδομένα, που έως τώρα κλιμακώνονται εύκολα μέχρι 10,000,000 παραδείγματα με χρήση παράλληλης και κατανεμημένης επεξεργασίας. Σκοπός αυτής της έρευνας είναι να ανεβάσουμε το όριο και την ταχύτητα λειτουργία των αλγορίθμων αυτών σε Μεγάλα Δεδομένα, με χρήση παράλληλης επεξεργασίας σε κάρτες γραφικών (GPGPU). Επιπλέον, σκόπος της τρέχουσας έρευνας είναι η διερεύνηση επεκτάσεων και βελτιώσεων των ήδη υλοποιημένων αλγορίθμων καθώς και η εφαρμογή τους σε διαφορετικά προβλήματα Μεγάλων Δεδομένων.

ΟΙ ΠΛΕΥΡΕΣ ΤΟΥ ΠΡΟΒΛΗΜΑΤΟΣ
Η διαχείριση των Μεγάλων Δεδομένων είναι ένα πολύπλευρο πρόβλημα. Εκτός από τον όγκο τους, τα Μεγάλων Δεδομένων παρουσιάζουν άλλα χαρακτηριστικά [Hu 2014] που τα διαχωρίζουν από τα παραδοσιακά δεδομένα ((Ποιά είναι αυτά;)). Ως εκ τούτου, ο σχεδιασμός κλιμακούμενων συστημάτων για ανάλυση Μεγάλων Δεδομένων αντιμετωπίζει πολλές τεχνικές προκλήσεις [Hu 2014]. Ενώ είναι δύσκολος ο χειρισμός του τεράστιου όγκου των δεδομένων, των διαφορετικών τύπων τους (static, dynamic, data streams κλπ) και των διαφορετικών μορφών τους (format), γίνεται περισσότερο δύσκολο να βγάλουμε λογικά συμπεράσματα από αυτά, μέσω της ανακάλυψης χρήσιμης γνώσης ((Τι είναι η χρήσιμη γνώση;)).
 [Hu 2014] H. Hu, Y.Wen, T.-S. Chua, and X. Li, “Toward scalable systems for Big data analytics: a technology tutorial,” IEEE Access, vol. 2, pp. 652–687, 2014.
Η πλειοψηφία των συστημάτων και εφαρμογών για Μεγάλα Δεδομένα, συνήθως αποτελούν το κάθε ένα μία λύση εντοπισμένη σε συγκεκριμένο ξεχωριστό πρόβλημα, για αυτό και στρέφονται στα παραδοσιακά παραδείγματα υπολογιστικής. Μέχρι πρόσφατα τομείς Μεγάλων Δεδομένων υπήρχαν μόνο σε εξειδικευμένα πεδία εφαρμογής, όπως της Μετεωρολογίας, της Φυσικής, και των Internet analytics. Σήμερα, οι εφαρμογές Μεγάλων Δεδομένων εισχωρούν σε πιο γενικά πεδία έρευνας όπως της βιολογίας, ιατρικής επιστήμης, γενετικής, βιοϊατρικής και της βιοπληροφορικής.
Ο όγκος των δεδομένων αυξάνεται εκθετικά με το χρόνο. Πρόσφατες μελέτες που συνοψίζονται στην [Gantz 2012] δείχνουν ότι η ποσότητα των παραγόμενων δεδομένων διπλασιάζεται κάθε 2 χρόνια. Προβλέπεται ενδεικτικά ότι ο συνολικός όγκος δεδομένων ((ο οποίος παράγεται από ποιούς;)) θα αυξηθεί από 130 exabytes που ήταν το έτος 2005, σε πάνω από 40,000 exabytes το έτος 2020. Έτσι η σημερινή κατάσταση δείχνει ότι ο ρυθμός αύξησης στην επεξεργαστική ισχύ είναι μικρότερος από το ρυθμό αύξησης του όγκου δεδομένων. Νέες προσεγγίσεις, μέθοδοι και αλγόριθμοι προς την κατεύθυνση Μηχανικής Μάθησης και ανακάλυψης γνώσης από μεγάλους όγκους δεδομένων είναι επιτακτικές.
[Gantz 2012] J. Gantz and D. Reinsel, “The digital universe in 2020: Big data, bigger digital shadows, and biggest growth in the far East,” in Proceedings of the IDC iView, IDC: Analyze the Future, 2012.

Ένας αποτελεσματικός τρόπος για την επεξεργασία Μεγάλων Δεδομένων  είναι η χρήση μονάδων επεξεργασίας γραφικών στη θέση των επεξεργαστών για την εκτέλεση υπολογισμών γενικού σκοπού, γνωστή ως Εκτέλεση Υπολογισμών Γενικού Σκοπού σε Μονάδες Επεξεργασίας Γραφικών (GPGPU). Οι μονάδες επεξεργασίας γραφικών αποτελούν συσκευές, οι οποίες έχουν σαν σκοπό την ελάφρυνση του φόρτου της Κεντρικής Μονάδας Επεξεργασίας μέσω του υπολογισμού μαθηματικών πράξεων που σχετίζονται με την απόδοση γραφικών στην οθόνη. Σε αντίθεση με τις Κεντρικής Μονάδας Επεξεργασίας οι οποίες είναι σχεδιασμένες για την επεξεργασία σειριακού κώδικα λόγω της χρήσης περισσότερων κυκλωμάτων για λειτουργίες ελέγχου ροής και προσωρινής αποθήκευσης δεδομένων, οι Μονάδες Επεξεργασίας Γραφικών ακολουθούν εξ ορισμού ένα μοντέλο παράλληλης επεξεργασίας δεδομένων. Το μοντέλο αυτό είναι δομημένο γύρω από ένα αγωγό δεδομένων (data pipeline) ο οποίος αποτελείται από διαφορετικά τμήματα επεξεργασίας από όπου πρέπει να περάσει ένα πολύγωνο ώστε να προτού εμφανιστεί στην οθόνη. Αρχικά, τα τμήματα αυτά ήταν σταθερού σκοπού, είχαν καθορισμένες λειτουργίες δηλαδή οι οποίες δεν ήταν δυνατόν να τροποποιηθούν από το χρήστη. Η αρχιτεκτονική των Μονάδων Επεξεργασίας Γραφικών αναβαθμίστηκε το 2001, μετατρέποντας τα παραπάνω τμήματα επεξεργασίας σε προγραμματιζόμενα, επιτρέποντας στον τελικό χρήστη να τροποποιήσει τη λειτουργία τους [Owens 2005]. Το CUDA αποτελεί ένα αφαιρετικό σύνολο εντολών προγραμματισμού το οποίο κυκλοφόρησε το 2007 για να επιτρέψει στους χρήστες την εύκολη συγγραφή πολυ-νηματικών (multi-threaded) παράλληλων εφαρμογών σε Μονάδες Επεξεργασίας Γραφικών, χωρίς τη χρήση κλήσεων κώδικα χαμηλού επιπέδου.

[J.D. Owens. Streaming Architectures and Technology Trends. In ACM SIGGRAPH 2005 Courses. ACM, 2005]


Εδώ περιγράφουμε τι θα κάνουμε (Parallel pipeline GPUs, Ensemble GPUs).
Δηλαδή θα μετρήσουμε μόνο τους χρόνους? Όχι,  θα πρέπει να δοκιμάσουμε και νέες προσεγγίσεις που θα είναι επιτρέπουν τον συγκερασμό των παράλληλων και κατανεμημένων αλγορίθμων Μηχανικής Μάθησης που έχουμε αναπτύξει έως τώρα, με τα συστήματα GPUs.

2 Εννοιολογικό πλαίσιο
Σε αυτή την ενότητα περιγράφουμε της βασικές έννοιες για το τι είναι Μηχανική Μάθηση, data mining, clustering, classification, regression, Νευρωνικά Δίκτυα, Ensembles και Committees.
ΜΗΧΑΝΙΚΗ ΜΑΘΗΣΗ (Machine Learning)
Κατά την διάρκεια της μάθησης ο άνθρωπος (ή ένα σύστημα) αλλάζει εσωτερικά, μαθαίνει και προσαρμόζεται συνεχώς στα εξωτερικά ερεθίσματα από το περιβάλλον του. Οι ανθρώπινες προσπάθειες μίμησης αυτής της διαδικασίας με χρήση υπολογιστικών μηχανών και μαθηματικών μοντέλων περιγράφονται από τη Μηχανική Μάθηση. Η Μηχανική Μάθηση [Mitchell 1997] [Hastie 2008] [Smola 2010] [Welling 2010], ένας κλάδος της τεχνητής νοημοσύνης, είναι μία περιοχή έρευνας για το σχεδιασμό και ανάπτυξη αλγορίθμων που επιτρέπουν στους υπολογιστές να εξελίξουν συμπεριφορές βασισμένες σε εμπειρικά δεδομένα, όπως αυτά που προέρχονται από αισθητήρες ή βάσεις δεδομένων. Οι αλγόριθμοι Μηχανικής Μάθησης χρησιμοποιούνται ευρύτατα στην ακαδημαϊκή κοινότητα, στη βιομηχανία και στις επιχειρήσεις λύνοντας πολλά πραγματικά προβλήματα ((ποιά είναι αυτά;)). Τα δεδομένα είναι παραδείγματα που περιγράφουν συσχετίσεις μεταξύ παρατηρούμενων μεταβλητών. Ένας αλγόριθμος μάθησης από παραδείγματα πρέπει να μπορεί να συλλάβει τα χαρακτηριστικά της άγνωστης κατανομής πιθανότητας που περιγράφει τα δεδομένα αυτά. Σημαντικό κομμάτι έρευνας στη Μηχανική Μάθηση αποτελεί η αυτόματη αναγνώριση σύνθετων προτύπων. Η δυσκολία βρίσκεται στο γεγονός ότι οι συνδυασμοί όλων των πιθανά μοντέλα όλων των πιθανών δεδομένων εισόδου είναι πάρα πολλές για να καλυφθούν από το σύνολο των παραδειγμάτων εκπαίδευσης. Έτσι ο αλγόριθμος μάθησης πρέπει να γενικεύσει από τα παραδείγματα, ώστε να είναι σε θέση να παραγάγει μια χρήσιμη εκτίμηση σε νέες υποθέσεις. Την τελευταία δεκαετία, λόγω της εκθετικής αύξησης των διαθέσιμων δεδομένων, η Μηχανική Μάθηση έχει γίνει κομμάτι της καθημερινότητας (για παράδειγμα παροχή εξατομικευμένων προτάσεων από μηχανές αναζήτησης με βάση το ιστορικό αναζητήσεων του χρήστη). Η τεράστια αύξηση των δεδομένων έχει αλλάξει την ροή έρευνας από εξεζητημένους αλγορίθμους υψηλής πολυπλοκότητας που λειτουργούν μόνο με λίγα δεδομένα, προς την κατεύθυνση εύρεσης λιγότερο πολύπλοκων αλγορίθμων που μπορούν όμως να λειτουργήσουν με μεγάλους όγκους δεδομένων. Μερικές υποκατηγορίες και μέθοδοι της Μηχανικής Μάθησης τις οποίες μελετήσαμε έως τώρα είναι Artificial Neural Networks [INS 2015] [EANN 2013] [BCI 2013] [SETN 2012][JCS 2016] [ICTAI 2012] [Neucom 2015] [PCI 2015] [AIAI 2014] [AIRE 2014] [IISA 2013] [AIAI 2012], kernel based methods [NCA 2016] [EANN 2015], clustering algorithms [AIAI 2016], Bayesian methods [BCI 2013] [SETN 2012][JCS 2016], Ensembles [Neucom 2015] [PCI 2015] [AIAI 2014], Committee Machines [AIRE 2014] [IISA 2013] [AIAI 2012].
[Mitchell 1997] Mitchell T., Machine Learning. Burr Ridge, IL: Mcgraw Hill, 1997.
[Hastie 2008] T. Hastie, R. Tibshirani and J. Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition, Springer 2008
[Smola 2010] Smola A. and Vishwanathan S.V.N., Introduction to Machine Learning, Cambridge University Press 2010.
[Welling 2010] Welling M., A First Encounter with Machine Learning, Donald Bren School of Information and Computer Science, University of California Irvine, 2010

CLUSTERING : Η Συσταδοποίηση (clustering, Unsupervised learning, Segmentation, Partitioning) είναι η διαδικασία ομαδοποίησης αντικειμένων με όμοια χαρακτηριστικά και η κατάταξή τους σε συστάδες ή συμπλέγματα. Στην Συσταδοποίηση οι συστάδες δεν είναι προκαθορισμένες αλλά προσδιορίζονται από τα δεδομένα. Η συσταδοποίηση αναφέρεται εναλλακτικά και σαν μη εποπτευόμενη μάθηση. Μπορεί να θεωρηθεί σαν μια διαμέριση ή τμηματοποίηση των δεδομένων σε ομάδες που μπορεί να είναι ή να μην είναι διακριτές μεταξύ τους. Η συσταδοποίηση συνήθως επιτυγχάνεται με τον καθορισμό του βαθμού ομοιότητας, ως προς προκαθορισμένα γνωρίσματα, ανάμεσα στα δεδομένα. Τα πιο σχετικά δεδομένα ομαδοποιούνται σε ίδιες ομάδες. Έως τώρα έχουμε δημοσιεύσει έναν δικό μας αλγόριθμο στην εργασία [AIAI 2016].
CLASSIFICATION: Η κατηγοριοποίηση, (classification, Supervised learning) αντιστοιχίζει τα δεδομένα σε προκαθορισμένες κατηγορίες ή κλάσεις. Αναφέρεται συχνά σαν εποπτευόμενη μάθηση επειδή οι κατηγορίες– κλάσεις καθορίζονται πριν ακόμη εξεταστούν τα δεδομένα. Οι αλγόριθμοι κατηγοριοποίησης, οι γνωστοί ταξινομητές, απαιτούν οι κατηγορίες να ορίζονται με βάση τις τιμές των γνωρισμάτων των δεδομένων, και περιγράφουν τις κατηγορίες εξετάζοντας τα γνωρίσματα αυτά. Μέχρι τώρα έχουμε ερευνήσει αλγορίθμους και εφαρμογές Κατηγοριοποίησης μέσω Νευρωνικών Δικτύων στις εργασίες [INS 2015] [EANN 2013] [BCI 2013] [SETN 2012][JCS 2016] [ICTAI 2012] [Neucom 2015] [PCI 2015] [AIAI 2014] [AIRE 2014] [IISA 2013] [AIAI 2012].
REGRESSION: Η Παλινδρόμηση (Regression) είναι μια ευρέως χρησιμοποιημένη στατιστική τεχνική μοντελοποίησης για την έρευνα της συσχέτισης μεταξύ μίας εξαρτώμενης μεταβλητής και μιας ή περισσότερων ανεξάρτητων μεταβλητών. Έτσι η παλινδρόμηση μπορεί να απεικονίζει ένα στοιχειώδες δεδομένο x σε μια πραγματική μεταβλητή πρόβλεψης y. Η παλινδρόμηση περιλαμβάνει την εκμάθηση μιας συνάρτησης y=f(x) που κάνει αυτή την απεικόνιση. Η παλινδρόμηση προϋποθέτει ότι τα σχετικά δεδομένα ταιριάζουν με μερικά γνωστά είδη συνάρτησης (γραμμική, μη-γραμμική, πολυωνυμική κλπ.) και στη συνέχεια καθορίζει την καλύτερη συνάρτηση αυτού του είδους που μοντελοποιεί τα δεδομένα. Τα Τεχνητά νευρωνικά δίκτυα χρησιμοποιούνται ευρύτατα για εκτίμηση σημείων, εκτίμηση συνάρτησης, παλινδρόμηση, πρόβλεψη, κατηγοριοποίηση. Έως τώρα έχουμε ερευνήσει αλγορίθμους και εφαρμογές Παλινδρόμησης μέσω Νευρωνικών Δικτύων στις εργασίες [COIN 2017] [NCA 2016] [EANN 2015] [PCI 2015].
NEURAL NETWORKS: Τα τεχνητά νευρωνικά δίκτυα (artificial neural networks - ANN) είναι μία προσπάθεια εφαρμογής των αρχών λειτουργίας του ανθρωπίνου εγκεφάλου, με μοντελοποίηση και κατανόηση των απλών λειτουργιών του και δυνατότητες υλοποίησης. Υποστηρίζουν έτσι μη γραμμικότητα, έχουν απλές υπολογιστικές μονάδες και μεγάλο αριθμό συνδέσεων (συνάψεων). Τα προβλήματα που καλούνται να λύσουν είναι Προσέγγιση συνάρτησης, αναγνώριση προτύπων, κατηγοριοποίηση, Ομαδοποίηση, Πρόβλεψη σημάτων, αναγνώριση συστημάτων, Συσχετιστική μνήμη, εξαγωγή χαρακτηριστικών, Αυτόματος έλεγχος, Βελτιστοποίηση κ.α. Πολλά βασικά χαρακτηριστικά του ανθρώπινου εγκεφάλου που λείπουν από τις αρχιτεκτονικές των υπολογιστών τύπου von Neumann, αλλά απαντώνται σε ένα βαθμό στα τεχνητά νευρωνικά δίκτυα είναι: μη-γραμμικότητα, Μαζική παραλληλία,  Κατανεμημένη αναπαράσταση, Κατανεμημένη επεξεργασία, Ικανότητα μάθησης, Ικανότητα γενίκευσης, Ικανότητα αφαίρεσης, Προσαρμοστικότητα, Ανοχή σε σφάλματα. Τα τεχνητά νευρωνικά δίκτυα είναι μια συλλογή από νευρώνες (μονάδες επεξεργασίας) που συνδέονται μεταξύ τους με συνάψεις/συνδέσεις. Κάθε νευρώνας έχει πολλές εισόδους αλλά μόνο μία έξοδο η οποία με τη σειρά της μπορεί να αποτελέσει είσοδο για άλλους νευρώνες. Οι συνδέσεις μεταξύ των νευρώνων διαφέρουν ως προς τη σημαντικότητά τους, η οποία και προσδιορίζεται από το συντελεστή βάρους. Η επεξεργασία μέσα σε κάθε νευρώνα καθορίζεται από τη συνάρτηση μεταφοράς, η οποία καθορίζει την κάθε έξοδο σε σχέση με τις εισόδους και τους συντελεστές βάρους. Η εκπαίδευση των νευρωνικών δικτύων μπορεί να θεωρηθεί μία μέθοδος εύρεσης των βέλτιστων παραμέτρων και βαρών τους. Μέχρι τώρα έχουμε ερευνήσει τους ακόλουθους τύπους Νευρωνικών Δικτύων:
Regularization Networks [NCA 2016] [EANN 2015]
Hierarchical Radial Basis Function Neural Networks [INS 2015] [EANN 2013]
Probabilistic Neural Networks [BCI 2013] [SETN 2012][JCS 2016]
Radial Basis Probabilistic Neural Network [ICTAI 2012]
Incremental Extreme Learning Machines [COIN 2017]
Ensembles of several neural networks [Neucom 2015] [PCI 2015] [AIAI 2014]
Committee Machine of several neural networks [AIRE 2014] [IISA 2013] [AIAI 2012]
ENSEMBLES AND COMMITTEE MACHINES: Οι Κατανεμημένοι ταξινομητές είναι τα πιο γνωστά παραδείγματα των αλγορίθμων κατανεμημένης εξόρυξης γνώσης. Τέτοιοι αλγόριθμοι βασίζονται στην προσέγγιση των ομάδων ταξινομητών (Ensembles) [Dietterich 2000]. Οι ομάδες ταξινομητών εμφανίστηκαν για να βελτιώσουν την ακρίβεια των μοντέλων μάθησης. Στην πράξη, πολλαπλά μοντέλα εξάγονται από ομοιογενείς διαμερίσεις των δεδομένων χρησιμοποιώντας και διαφορετικές μεθόδους. Τα τοπικά μοντέλα συναθροίζονται με την υιοθέτηση ενός (σταθμισμένου ή όχι) σχήματος ψηφοφορίας (voting). Αυτή η προσέγγιση μπορεί να πραγματοποιηθεί απευθείας σε ένα κατανεμημένο περιβάλλον (αν κάθε πηγή δεδομένων έχει ένα αντιπροσωπευτικό υποσύνολο δεδομένων). Έως τώρα έχουμε ερευνήσει αλγορίθμους που αφορούν Ensembles και Committee Machines Νευρωνικών Δικτύων στις εργασίες [Neucom 2015] [PCI 2015] [AIAI 2014] [AIRE 2014] [IISA 2013] [AIAI 2012].

3 Μεθοδολογία
Σε αυτό την ενότητα παρουσιάζουμε την βασική μεθοδολογία για Παράλληλους και κατανεμημένους αλγόριθμους (από την διατριβή) , GPUs κλπ
ΠΡΕΠΕΙ ΝΑ ΒΑΛΩ ΚΑΙ ΜΕΡΙΚΑ ΑΠΟ ΤΟ ABSTRACT
ΝΑ ΔΕΙΞΩ ΑΥΤΑ ΠΟΥ ΚΆΝΑΜΕ ΗΔΗ
Για μία περίοδο τριών δεκαετιών τα τεχνητά νευρωνικά δίκτυα, η παράλληλη και κατανεμημένη επεξεργασία και η Μηχανική Μάθηση με την ανακάλυψη γνώσης από δεδομένα συνεχίζουν να αναπτύσσονται και να εξελίσσονται. Όλο και περισσότερο συχνότερα στις μέρες μας συνεργάζονται και συνδυάζονται μεταξύ τους λόγω των καθημερινών και αυξημένων αναγκών για ανάλυση μεγάλων όγκων δεδομένων.

DATA- TASK PARALLELISM
Ο παραλληλισμός δεδομένων (data parallelism) αναφέρεται στην εκτέλεση της ίδιας λειτουργίας ή εντολής σε πολλαπλά μεγάλα υποσύνολα δεδομένων συγχρόνως. Αυτό είναι σε αντίθεση με τον παραλληλισμό διεργασιών (task parallelism), που λέγεται και παραλληλισμός ελέγχου ή παραλληλισμός λειτουργιών, ο οποίος αναφέρεται στην ταυτόχρονη εκτέλεση πολλαπλών διαδικασιών ή εντολών. Παρά τα πλεονεκτήματα του παραλληλισμού δεδομένων, πρέπει να υπογραμμιστεί ότι η αξιοποίηση του παραλληλισμού διεργασιών είναι επίσης κρίσιμης σημασίας στην εξόρυξη γνώσης από δεδομένα. Αξίζει να σημειωθεί ότι ο παραλληλισμός δεδομένων και διεργασιών δεν είναι αμοιβαία αποκλειόμενοι. Εάν είναι διαθέσιμος ένας αρκετά μεγάλος αριθμός επεξεργαστών, και οι δύο τύποι παραλληλισμών μπορούν να χρησιμοποιηθούν συγχρόνως, οι οποίοι μπορούν να επιταχύνουν πολύ την εκτέλεση των αλγορίθμων εξόρυξης. Αν και αυτό αποτελεί μεγάλη πρόκληση, όταν υλοποιείται ένας τέτοιος υβριδικός παραλληλισμός είναι συνήθως πολύ αποτελεσματικός. Αυτός ο υβριδικός data-task parallelism είναι η κύρια βάση των περισσότερων έως τώρα εργασιών μας πάνω στο θέμα και αποτελεί και την βάση πάνω στην οποία θα συνεχίσουμε αυτή την έρευνα επεκτείνοντας την στα συστήματα GPUs.

ΜΟΝΑΔΕΣ ΕΠΕΞΕΡΓΑΣΙΑΣ ΓΡΑΦΙΚΩΝ
Παρότι ο τυπικός παραλληλισμός μειώνει το χρόνο επεξεργασίας, αυτό δεν είναι από μόνο του αρκετό, καθότι ο αρχικός χρόνος υπολογισμού T στην καλύτερη περίπτωση διαιρείται δια τον αριθμό των επεξεργαστών Τ/P, και έτσι έχουμε επιτάχυνση P φορές. Η χρήση πολλών CPUs δεν είναι από μόνη της αρκετή. Χρειάζεται μία πιο εξελιγμένη αρχιτεκτονική που θα βασίζεται σε GPUs που πλεονεκτούν έναντι των απλών CPUs σε ταχύτητα. Πρέπει λοιπόν σε κάθε έναν επεξεργαστή να εφαρμοστεί επιτάχυνση των τοπικών διεργασιών με επιπλέον χρήση GPUs ((++)).

Μέχρι τώρα έχουμε μελετήσει την αποδοτική εφαρμογή διαφορετικών κατηγοριών προβλημάτων παράλληλα με τη χρήση Μονάδων Επεξεργασίας Γραφικών. Στο [PCI 2012] παρουσιάσαμε πειραματικά αποτελέσματα από την παράλλη υλοποίηση των αλγορίθμων αναζήτησης προτύπων Naive, Knuth-Morris-Pratt, Boyer-Moore-Horspool και Quick-Search και την εκτέλεση τους σε βιολογικά δεδομένα. Στο [ΑΙΑΙ 2012b] εξετάσαμε την απόδοση του αλγορίθμου αναζήτησης πολλαπλών προτύπων Wu-Manber σε Μονάδες Επεξεργασίας Γραφικών με τη χρήση του συνόλου εντολών προγραμματισμού OpenCL. Στο [IJAIT 2015] μελετήσαμε την άπόδοση του αλγορίθμου Wu-Manber όταν υλοποιηθεί παράλληλα σε πολλαπλές Μονάδες Επεξεργασίας Γραφικών συνδεδεμένες σε συστοιχία υπολογιστών με τη χρήση του συνόλου CUDA και την εκτέλεσή τους σε βιολογικά δεδομένα. Επιπλέον, έγινε εκτεταμένη μελέτη διαφορετικών τεχνικών παράλληλης βελτιστοποίησης και κατόπιν σύγκριση μεταξύ των διαφορετικών τεχνικών αυτών. Στο [SCPE 2015] έγινε υλοποίηση των αλγορίθμων πολλαπλής αναζήτησης προτύπων Aho-Corasick, Set Horspool, Set Backward Oracle Matching, Wu-Manber και SOG παράλληλα σε Μονάδες Επεξεργασίας Γραφικών και εκτίμηση της απόδοσης των υλοποιήσεων κατόπιν της εφαρμογής διαφορετικών τεχνικών παράλληλης βελτιστοποίησης.






ENSEMBLE GPUs


4 Καινοτομία της ερευνητικής πρότασης
Η καινοτομία της ερευνητικής πρότασης και ο βασικός στόχος είναι η αντιστοίχηση των μοντέλων εκμάθησης (task) και των δεδομένων (data) σε δύο αρχιτεκτονικές:
          αρχιτεκτονική parallel ring pipeline task-data
          αρχιτεκτονική distributed task-data
 που επιτρέπουν την εκμάθηση μεγάλων μοντέλων (που είναι κατανεμημένα σε πολλούς επεξεργαστές) από μεγάλο σύνολο δεδομένων (που είναι κατανεμημένο σε πολλούς επεξεργαστές).

Α)  αρχιτεκτονική data-task parallelism in a ring pipeline
For dealing with the scalability problem we propose parallel mappings in a Ring pipeline. In order to facilitate constructing a large scale distributed model on a large scale distributed dataset we demonstrate that the entire learning scheme can use simultaneously data-neuron partitioning across many processors. While this partitioning complicates the data-task dependency graph and maximizes the communication overhead the processors can be organized in a virtual ring pipeline.
What the ring pipeline architecture does is to minimize communication links between the processors by reducing the data-task dependency graph into a cycle, where we can adopt the {send-compute-receive} pattern which also permits to overlap the computation delays with the communication delays.
What the ring pipeline architecture does is: 1) reduce the data-task dependency graph into a cycle, 2) minimizes the number of communication links, 3) can use the {send-compute-receive} pattern that permits overlapping computation delays with communication delays.
Hence, the essence of the data-neuron parallelism we employ is based on this ring pipeline parallel architecture, which is known for not suffering from common scalability problems, communication delays and bottleneck effects. It allows each processor node to hold a part of the neurons in the learning model together with a part of the training data.
In fig. 1.2(c) we especially adopt the Ring pipeline parallel architecture for data-task parallelism. In the ring pipelining every processor has a portion of tasks (neurons) and a portion of the training data. There is a single program all processors execute with no synchronization points. Like pipeline every processor passes a message to its next and receives a message from its previous.
Η αρχιτεκτονική παράλληλης σωληνωτής επεξεργασίας σε δακτύλιο επιτρέπει την εκπαίδευση ενός μεγάλου μοντέλου μάθησης που κατανέμεται σε πολλούς επεξεργαστές, χρησιμοποιώντας ένα μεγάλο σύνολο δεδομένων που είναι και αυτό κατανεμημένο σε πολλούς επεξεργαστές. Την αρχιτεκτονική παράλληλης σωληνωτής επεξεργασίας σε δακτύλιο την έχουμε ήδη επιτυχημένα χρησιμοποιήσει στην εργασία [JCS 2016].

Β) Αρχιτεκτονική Distributed Task-Data
Τυπικά οι κατανεμημένοι αλγόριθμοι ανακάλυψη γνώσης σχεδιάζονται σύμφωνα με τον πιθανό παραλληλισμό που μπορούν να εφαρμόσουν πάνω στα κατανεμημένα δεδομένα, καθώς τα δεδομένα αυτά δεν μπορούν να συγκεντρωθούν σε έναν κεντρικό server. Η κατανεμημένη μάθηση και ανακάλυψη γνώσης από απομονωμένες τοποθεσίες δεδομένων (κλειστά συστήματα όπου κάθε επεξεργαστής έχει πρόσβαση στο δικό του υποσύνολο δεδομένων) είναι μία στρατηγική ανεξάρτητου παραλληλισμού που χρησιμοποιεί ασύγχρονη μεταβίβαση μηνυμάτων (asynchronous message passing). Η ανταλλαγή μηνυμάτων είναι όλοι-με-όλους (all-to-all).

Κάθε επεξεργαστής έχει ένα πλήρες νευρωνικό μοντέλο (εδώ κάθε task είναι ένα μοντέλο) που εκπαιδεύεται με ένα υποσύνολο δεδομένων. Κατά συνέπεια περιλαμβάνουν τοπική ανάλυση δεδομένων, που ακολουθείται από την παραγωγή ενός καθολικού μοντέλου μέσω της συνάθροισης των τοπικών μοντέλων. Στη συνέχεια όλα τα τοπικά μοντέλα αθροίζονται για να παραγάγουν το τελικό μοντέλο περιγραφής. Αυτή την αρχιτεκτονική για κατανεμημένη μάθηση και ανακάλυψη γνώσης με Νευρωνικά Δίκτυα την έχουμε ήδη επιτυχημένα χρησιμοποιήσει σε αρκετές πρόσφατες εργασίες [Neucom 2015][AIRE 2014] [IISA 2013] [AIAI 2012].



5 Συνεισφορά στη θεωρητική ή/και εφαρμοσμένη επιστημονική γνώση
CLUSTERING
Έχουμε πρόσφατα δημοσιεύσει έναν νέο αλγόριθμο, τον KG-SC (Kernel Gradient Subtractive Clustering) [AIAI 2016] για αυτοματοποιημένο exemplar selection και Clustering, που είναι από τις βασικότερες λειτουργίες στο πεδίο Machine Learning και Data Mining. Είναι αρκετά εύκολο να δοκιμάσουμε τον KG-SC σε πολλά δεδομένα (για τα Μεγάλα Δεδομένα χρειάζεται να κάνουμε ένα dual tree), και να τον επεκτείνουμε επίσης σε Ιεραρχικό KG-SC, Streaming KG-SC, constrained KG-SC καθώς και Semi-Supervised ή Supervised KG-SC.
LOW RANK KERNEL MATRIX APPROXIMATION
Θα χρησιμοποιήσουμε τον αλγόριθμο KG-SC σε GPUs για Kernel matrix low rank approximation στα large scale Regularization Networks.
PARALLEL CLASSIFICATION
Με τον παράλληλο αλγόριθμο KG-SC σε GPUs και τον παράλληλο mini-batch gradient descent σε GPUs θα μπορούμε πλέον να υλοποιήσουμε: 1) Parallel mini-batch gradient descent for multi-output RBFNN (Radial Basis Function Neural Network) classifier, 2) Semi-Supervised Radial Basis Function Neural Networks, 3) Minimum Class-Variance guided RBFNN multi-output classifier

DISTRIBUTED ENSEMBLES FOR CLASSIFICATION
The weight base ensemble selection by using non-negative regularized least squares could be examined in the context of other models, like multi-label classification, that similarly require pruning.

Regression

DENSITY ESTIMATION ΣΕ GPUS
Θα χρησιμοποιήσουμε τον αλγόριθμο KG-SC σε GPUs μαζί με τον αλγόριθμο Expectation-Maximization σε GPUs για Density Estimation.

Ενδεχόμενη συμπερίληψη βιβλιογραφίας δεν προσμετρείται στον αριθμό των λέξεων

ΒΙΒΛΙΟΓΡΑΦΙΑ
[COIN 2017] Yiannis Kokkinos and Konstantinos G. Margaritis (2017) “Big data regression with Parallel Enhanced and Convex Incremental Extreme Learning Machines”, Computational Intelligence, accepted 2017.
[NCA 2016] Yiannis Kokkinos and Konstantinos G. Margaritis (2016) “Local Learning Regularization Networks for localized regression”. Neural Computing and Applications. DOI :10.1007/s00521-016-2569-0
[JCS 2016] Yiannis Kokkinos and Konstantinos G. Margaritis (2016) “Simulating parallel scalable Probabilistic Neural Networks via exemplar selection and EM in a Ring Pipeline”, Journal of Computational Science, under review
[AIAI 2016] Yiannis Kokkinos and Konstantinos G. Margaritis (2016) “Exemplar selection via leave-one-out kernel averaged gradient descent and Subtractive Clustering”, (AIAI 2016), Springer Lecture Notes in Computer Science, IFIP AICT 475, pages 1–13
[EANN 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015), “Multithreaded Local Learning Regularization Neural Networks for regression tasks”, (EANN 2015), Communications in Computer and Information Science, CCIS 517, pages 129–138
[IJAIT 2015] C.S. Kouzinopoulos, J.-A. M. Assael, T.K. Pyrgiotis and K.G. Margaritis (2015). "A Hybrid Parallel Implementation of the Wu-Manber Algorithm Using NVIDIA CUDA and MPI evaluated on a Biological Sequence Database",
International Journal on Artificial Intelligence Tools 2015.
[INS 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015) “Topology and simulations of Hierarchical Markovian Radial Basis Function Neural Network classifier”, Information Sciences, vol. 294, pages 612−624.
[Neucom 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015) “Confidence ratio Affinity Propagation in ensemble selection of neural network classifiers for distributed privacy-preserving data mining”, Neurocomputing, 150, pages 513−528.
[PCI 2015] Yiannis Kokkinos and Konstantinos G. Margaritis (2015). “A fast progressive Local Learning regression ensemble of Generalized Regression Neural Networks”. 19th Pan-Hellenic Conference on Informatics, PCI 2015.
[SCPE 2015] C.S. Kouzinopoulos, P.D. Michailidis and K.G. Margaritis (2015). "Multiple String Matching on a GPU using CUDA". Scalable Computing: Practice and Experience, 2015
[AIRE 2014] Yiannis Kokkinos and Konstantinos G. Margaritis (2014) “A distributed privacy-preserving regularization network committee machine of isolated Peer classifiers for P2P data mining”, Artificial Intelligence Review, 42(3), pages 385−402.
[AIAI 2014] Yiannis Kokkinos and Konstantinos G. Margaritis (2014) “Breaking ties of plurality voting in ensembles of distributed neural network classifiers using soft max accumulations”, (AIAI 2014), Springer Lecture Notes in Computer Science, IFIP AICT 436, pages 20–28.
[IISA 2013] Yiannis Kokkinos and Konstantinos G. Margaritis (2013) “Distributed privacy-preserving P2P data mining via Probabilistic Neural Network Committee Machines”, in 4th International Conference on Information, Intelligence, Systems, and Applications (IISA 2013)
[BCI 2013] Yiannis Kokkinos and Konstantinos G. Margaritis (2013) “Parallel and local learning for fast Probabilistic Neural Networks in scalable data mining”, in BCI 2013.
[EANN 2013] Yiannis Kokkinos and Konstantinos G. Margaritis (2013) “A Parallel and Hierarchical Markovian RBF Neural Network: preliminary performance evaluation”, (EANN 2013), Springer Lecture Notes in Computer Science, Part I, CCIS 383, pages 340–349
[AIAI 2012] Yiannis Kokkinos and Konstantinos G. Margaritis (2012) “A Regularization Network committee machine of isolated Regularization Networks for distributed privacy preserving data mining”, (AIAI 2012), Springer Lecture Notes in Computer Science, IFIP AICT 381, pages 97–106.
[AIAI 2012b] T.K. Pyrgiotis, C.S. Kouzinopoulos and K.G. Margaritis (2012) "Parallel Implementation of the Wu-Manber Algorithm Using the OpenCL Framework", Artificial Intelligence Applications and Innovations, AIAI 2012.
[ICTAI 2012] Yiannis Kokkinos and Konstantinos G. Margaritis (2012) “A Parallel Radial Basis Probabilistic Neural Network for scalable data mining in distributed memory machines”, 24th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2012.
[PCI 2012] C.S. Kouzinopoulos and K.G. Margaritis (2012) "String Matching on a multicore GPU using CUDA"
13th Pan-Hellenic Conference on Informatics, PCI 2009.
[SETN 2012] Yiannis Kokkinos and Konstantinos G. Margaritis (2012) “Parallelism, localization and chain gradient tuning combinations for fast scalable Probabilistic Neural Networks in data mining applications”,  Springer Lecture Notes in Artificial Intelligence 7297, pages 41–48.
